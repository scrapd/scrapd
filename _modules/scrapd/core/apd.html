
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>scrapd.core.apd &#8212; scrapd 3.0.4 documentation</title>
    <link rel="stylesheet" href="../../../_static/aiohttp.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
 
<link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />


<link rel="canonical" href="https://scrapd.github.io/scrapd/_modules/scrapd/core/apd.html"/>

<meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />
<link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet">

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for scrapd.core.apd</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Define the module containing the function used to scrap data from the APD website.&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urljoin</span>

<span class="kn">import</span> <span class="nn">aiohttp</span>
<span class="kn">from</span> <span class="nn">loguru</span> <span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">tenacity</span> <span class="kn">import</span> <span class="n">retry</span>
<span class="kn">from</span> <span class="nn">tenacity</span> <span class="kn">import</span> <span class="n">stop_after_attempt</span>
<span class="kn">from</span> <span class="nn">tenacity</span> <span class="kn">import</span> <span class="n">wait_exponential</span>

<span class="kn">from</span> <span class="nn">scrapd.core</span> <span class="kn">import</span> <span class="n">article</span>
<span class="kn">from</span> <span class="nn">scrapd.core</span> <span class="kn">import</span> <span class="n">constant</span>
<span class="kn">from</span> <span class="nn">scrapd.core</span> <span class="kn">import</span> <span class="n">date_utils</span>
<span class="kn">from</span> <span class="nn">scrapd.core</span> <span class="kn">import</span> <span class="n">model</span>
<span class="kn">from</span> <span class="nn">scrapd.core</span> <span class="kn">import</span> <span class="n">twitter</span>
<span class="kn">from</span> <span class="nn">scrapd.core.regex</span> <span class="kn">import</span> <span class="n">match_pattern</span>

<span class="n">APD_URL</span> <span class="o">=</span> <span class="s1">&#39;http://austintexas.gov/department/news/296&#39;</span>
<span class="n">PAGE_DETAILS_URL</span> <span class="o">=</span> <span class="s1">&#39;http://austintexas.gov/&#39;</span>


<div class="viewcode-block" id="fetch_text"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.fetch_text">[docs]</a><span class="nd">@retry</span><span class="p">(</span><span class="n">stop</span><span class="o">=</span><span class="n">stop_after_attempt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">wait</span><span class="o">=</span><span class="n">wait_exponential</span><span class="p">(</span><span class="n">multiplier</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="n">reraise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">fetch_text</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fetch the data from a URL as text.</span>

<span class="sd">    :param aiohttp.ClientSession session: aiohttp session</span>
<span class="sd">    :param str url: request URL</span>
<span class="sd">    :param dict params: request paramemters, defaults to None</span>
<span class="sd">    :return: the data from a URL as text.</span>
<span class="sd">    :rtype: str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
            <span class="k">return</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">()</span>
    <span class="k">except</span> <span class="p">(</span>
            <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientError</span><span class="p">,</span>
            <span class="n">aiohttp</span><span class="o">.</span><span class="n">http_exceptions</span><span class="o">.</span><span class="n">HttpProcessingError</span><span class="p">,</span>
    <span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;aiohttp exception for </span><span class="si">{url}</span><span class="s1"> -&gt; </span><span class="si">{e}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">raise</span> <span class="n">e</span></div>


<div class="viewcode-block" id="fetch_news_page"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.fetch_news_page">[docs]</a><span class="k">async</span> <span class="k">def</span> <span class="nf">fetch_news_page</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">page</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fetch the content of a specific news page from the APD website.</span>

<span class="sd">    The page number starts at 1.</span>

<span class="sd">    :param aiohttp.ClientSession session: aiohttp session</span>
<span class="sd">    :param int page: page number to fetch, defaults to 1</span>
<span class="sd">    :return: the page content.</span>
<span class="sd">    :rtype: str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">page</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;page&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="k">await</span> <span class="n">fetch_text</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">APD_URL</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span></div>


<div class="viewcode-block" id="fetch_detail_page"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.fetch_detail_page">[docs]</a><span class="k">async</span> <span class="k">def</span> <span class="nf">fetch_detail_page</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">url</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fetch the content of a detail page.</span>

<span class="sd">    :param aiohttp.ClientSession session: aiohttp session</span>
<span class="sd">    :param str url: request URL</span>
<span class="sd">    :return: the page content.</span>
<span class="sd">    :rtype: str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="k">await</span> <span class="n">fetch_text</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span></div>


<div class="viewcode-block" id="extract_traffic_fatalities_page_details_link"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.extract_traffic_fatalities_page_details_link">[docs]</a><span class="k">def</span> <span class="nf">extract_traffic_fatalities_page_details_link</span><span class="p">(</span><span class="n">news_page</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract the fatality detail page links from the news page.</span>

<span class="sd">    :param str news_page: html content of the new pages</span>
<span class="sd">    :return: a list of links.</span>
<span class="sd">    :rtype: list or `None`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        &lt;a\shref=&quot;</span>
<span class="sd">        (?:</span>
<span class="sd">            (?:</span>
<span class="sd">                (/news/traffic-fatality-\d{1,3}-\d|\S*)</span>
<span class="sd">                &quot;&gt;</span>
<span class="sd">                (Traffic\sFatality\s\#(\d{1,3}))</span>
<span class="sd">            )</span>
<span class="sd">            |</span>
<span class="sd">            (?:</span>
<span class="sd">                (/news/fatality-crash-\d{1,3}-\d)</span>
<span class="sd">                &quot;&gt;</span>
<span class="sd">                (Fatality\sCrash\s\#(\d{1,3}))</span>
<span class="sd">            )</span>
<span class="sd">        )</span>
<span class="sd">        .*\s*</span>
<span class="sd">        &lt;/a&gt;</span>
<span class="sd">        &#39;&#39;&#39;</span><span class="p">,</span>
        <span class="n">re</span><span class="o">.</span><span class="n">VERBOSE</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">MULTILINE</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="n">regex</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">news_page</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">MULTILINE</span><span class="p">)</span>
    <span class="n">compact_matches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">part</span> <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">match</span> <span class="k">if</span> <span class="n">part</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">compact_matches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">compact_matches</span></div>


<div class="viewcode-block" id="generate_detail_page_urls"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.generate_detail_page_urls">[docs]</a><span class="k">def</span> <span class="nf">generate_detail_page_urls</span><span class="p">(</span><span class="n">titles</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate the full URLs of the fatality detail pages.</span>

<span class="sd">    :param list titles: a list of partial link</span>
<span class="sd">    :return: a list of full links to the fatality detail pages.</span>
<span class="sd">    :rtype: list</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">urljoin</span><span class="p">(</span><span class="n">PAGE_DETAILS_URL</span><span class="p">,</span> <span class="n">title</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">title</span> <span class="ow">in</span> <span class="n">titles</span><span class="p">]</span></div>


<div class="viewcode-block" id="has_next"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.has_next">[docs]</a><span class="k">def</span> <span class="nf">has_next</span><span class="p">(</span><span class="n">news_page</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return `True` if there is another news page available.</span>

<span class="sd">    :param str news_page: the news page to parse</span>
<span class="sd">    :return: `True` if there is another news page available, `False` otherwise.</span>
<span class="sd">    :rtype: bool</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">news_page</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="n">pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="sa">r</span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        &lt;a                  # Beginning of the anchor</span>
<span class="sd">        \s+</span>
<span class="sd">        title=\&quot;[^\&quot;]*\&quot;    # Anchor tittle</span>
<span class="sd">        \s+</span>
<span class="sd">        href=\&quot;[^\&quot;]*\&quot;&gt;    # Anchor href</span>
<span class="sd">        (next\s›)            # Test indicating a next page</span>
<span class="sd">        &lt;/a&gt;                # End of the anchor.</span>
<span class="sd">        &#39;&#39;&#39;</span><span class="p">,</span>
        <span class="n">re</span><span class="o">.</span><span class="n">VERBOSE</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">MULTILINE</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">match_pattern</span><span class="p">(</span><span class="n">news_page</span><span class="p">,</span> <span class="n">pattern</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="n">element</span><span class="p">)</span></div>


<div class="viewcode-block" id="parse_page"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.parse_page">[docs]</a><span class="k">def</span> <span class="nf">parse_page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">dump</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse the page using all parsing methods available.</span>

<span class="sd">    :param str page: the content of the fatality page</span>
<span class="sd">    :param str url: detail page URL</span>
<span class="sd">    :return: a dictionary representing a fatality.</span>
<span class="sd">    :rtype: dict</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">Report</span><span class="p">(</span><span class="n">case</span><span class="o">=</span><span class="s1">&#39;19-123456&#39;</span><span class="p">)</span>

    <span class="c1"># Parse the twitter fields.</span>
    <span class="n">twitter_report</span><span class="p">,</span> <span class="n">twitter_err</span> <span class="o">=</span> <span class="n">twitter</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">twitter_report</span><span class="p">)</span>

    <span class="c1"># Parse the page.</span>
    <span class="n">article_report</span><span class="p">,</span> <span class="n">artricle_err</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">parse_content</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">article_report</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">twitter_err</span> <span class="ow">or</span> <span class="n">artricle_err</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
        <span class="n">twitter_err_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Twitter fields:</span><span class="se">\n\t</span><span class="s1"> * &#39;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n\t</span><span class="s2"> * &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">twitter_err</span><span class="p">)</span> <span class="k">if</span> <span class="n">twitter_err</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="n">article_err_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Article fields:</span><span class="se">\n\t</span><span class="s1"> * &#39;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n\t</span><span class="s2"> * &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">artricle_err</span><span class="p">)</span> <span class="k">if</span> <span class="n">artricle_err</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Errors while parsing </span><span class="si">{url}</span><span class="s1">:</span><span class="si">{twitter_err_str}{article_err_str}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="c1"># Dump the file.</span>
        <span class="k">if</span> <span class="n">dump</span><span class="p">:</span>
            <span class="n">dumpr_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">constant</span><span class="o">.</span><span class="n">DUMP_DIR</span><span class="p">)</span>
            <span class="n">dumpr_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">dump_file_name</span> <span class="o">=</span> <span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">dump_file</span> <span class="o">=</span> <span class="n">dumpr_dir</span> <span class="o">/</span> <span class="n">dump_file_name</span>
            <span class="n">dump_file</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">report</span></div>


<div class="viewcode-block" id="fetch_and_parse"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.fetch_and_parse">[docs]</a><span class="nd">@retry</span><span class="p">()</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">fetch_and_parse</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">dump</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse a fatality page from a URL.</span>

<span class="sd">    :param aiohttp.ClientSession session: aiohttp session</span>
<span class="sd">    :param str url: detail page URL</span>
<span class="sd">    :return: a dictionary representing a fatality.</span>
<span class="sd">    :rtype: dict</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Retrieve the page.</span>
    <span class="n">page</span> <span class="o">=</span> <span class="k">await</span> <span class="n">fetch_detail_page</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">page</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The URL </span><span class="si">{url}</span><span class="s1"> returned a 0-length content.&#39;</span><span class="p">)</span>

    <span class="c1"># Parse it.</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">parse_page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">dump</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">report</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;No data could be extracted from the page </span><span class="si">{url}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="c1"># Add the report link.</span>
    <span class="n">report</span><span class="o">.</span><span class="n">link</span> <span class="o">=</span> <span class="n">url</span>

    <span class="k">return</span> <span class="n">report</span></div>


<div class="viewcode-block" id="async_retrieve"><a class="viewcode-back" href="../../../api/scrapd.core.html#scrapd.core.apd.async_retrieve">[docs]</a><span class="k">async</span> <span class="k">def</span> <span class="nf">async_retrieve</span><span class="p">(</span><span class="n">pages</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">from_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attempts</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">backoff</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dump</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieve fatality data.</span>

<span class="sd">    :param str pages: number of pages to retrieve or -1 for all</span>
<span class="sd">    :param str from_: the start date</span>
<span class="sd">    :param str to: the end date</span>
<span class="sd">    :param int attempts: number of attempts per report</span>
<span class="sd">    :param int backoff: initial backoff time (second)</span>
<span class="sd">    :param bool dump: dump reports with parsing issues</span>
<span class="sd">    :return: the list of fatalities and the number of pages that were read.</span>
<span class="sd">    :rtype: tuple</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">has_entries</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">no_date_within_range_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">from_date</span> <span class="o">=</span> <span class="n">date_utils</span><span class="o">.</span><span class="n">from_date</span><span class="p">(</span><span class="n">from_</span><span class="p">)</span>
    <span class="n">to_date</span> <span class="o">=</span> <span class="n">date_utils</span><span class="o">.</span><span class="n">to_date</span><span class="p">(</span><span class="n">to</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Retrieving fatalities from </span><span class="si">{from_date}</span><span class="s1"> to </span><span class="si">{to_date}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># Fetch the news page.</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fetching page </span><span class="si">{page}</span><span class="s1">...&#39;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">news_page</span> <span class="o">=</span> <span class="k">await</span> <span class="n">fetch_news_page</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">page</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Cannot retrieve news page #</span><span class="si">{page}</span><span class="s1">.&#39;</span><span class="p">)</span>

            <span class="c1"># Looks for traffic fatality links.</span>
            <span class="n">page_details_links</span> <span class="o">=</span> <span class="n">extract_traffic_fatalities_page_details_link</span><span class="p">(</span><span class="n">news_page</span><span class="p">)</span>

            <span class="c1"># Generate the full URL for the links.</span>
            <span class="n">links</span> <span class="o">=</span> <span class="n">generate_detail_page_urls</span><span class="p">(</span><span class="n">page_details_links</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;{len(links)} fatality page(s) to process.&#39;</span><span class="p">)</span>

            <span class="c1"># Fetch and parse each link.</span>
            <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">fetch_and_parse</span><span class="o">.</span><span class="n">retry_with</span><span class="p">(</span>
                    <span class="n">stop</span><span class="o">=</span><span class="n">stop_after_attempt</span><span class="p">(</span><span class="n">attempts</span><span class="p">),</span>
                    <span class="n">wait</span><span class="o">=</span><span class="n">wait_exponential</span><span class="p">(</span><span class="n">multiplier</span><span class="o">=</span><span class="n">backoff</span><span class="p">),</span>
                    <span class="n">reraise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)(</span><span class="n">session</span><span class="p">,</span> <span class="n">link</span><span class="p">,</span> <span class="n">dump</span><span class="p">)</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span>
            <span class="p">]</span>
            <span class="n">page_res</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">page_res</span><span class="p">:</span>
                <span class="c1"># If the page contains fatalities, ensure all of them happened within the specified time range.</span>
                <span class="n">entries_in_time_range</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">entry</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">page_res</span> <span class="k">if</span> <span class="n">date_utils</span><span class="o">.</span><span class="n">is_between</span><span class="p">(</span><span class="n">entry</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">from_date</span><span class="p">,</span> <span class="n">to_date</span><span class="p">)</span>
                <span class="p">]</span>

                <span class="c1"># If 2 pages in a row:</span>
                <span class="c1">#   1) contain results</span>
                <span class="c1">#   2) but none of them contain dates within the time range</span>
                <span class="c1">#   3) and we did not collect any valid entries</span>
                <span class="c1"># Then we can stop the operation.</span>
                <span class="n">past_entries</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="n">date_utils</span><span class="o">.</span><span class="n">is_before</span><span class="p">(</span><span class="n">entry</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">from_date</span><span class="p">)</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">page_res</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">from_</span> <span class="ow">and</span> <span class="n">past_entries</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">has_entries</span><span class="p">:</span>
                    <span class="n">no_date_within_range_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">no_date_within_range_count</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;{len(entries_in_time_range)} fatality page(s) within the specified time range.&#39;</span><span class="p">)</span>
                    <span class="k">break</span>

                <span class="c1"># Check whether we found entries in the previous pages.</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">has_entries</span><span class="p">:</span>
                    <span class="n">has_entries</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">has_entries</span> <span class="ow">and</span> <span class="nb">bool</span><span class="p">(</span><span class="n">entries_in_time_range</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;{len(entries_in_time_range)} fatality page(s) is/are within the specified time range.&#39;</span><span class="p">)</span>

                <span class="c1"># If there are none in range, we do not need to search further, and we can discard the results.</span>
                <span class="k">if</span> <span class="n">has_entries</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">entries_in_time_range</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;There are no data within the specified time range on page </span><span class="si">{page}</span><span class="s1">.&#39;</span><span class="p">)</span>
                    <span class="k">break</span>

                <span class="c1"># Store the results if the ID number is new.</span>
                <span class="n">res</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">entry</span><span class="o">.</span><span class="n">case</span><span class="p">:</span> <span class="n">entry</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">entries_in_time_range</span> <span class="k">if</span> <span class="n">entry</span><span class="o">.</span><span class="n">case</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">res</span><span class="p">})</span>

            <span class="c1"># Stop if there is no further pages.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_next</span><span class="p">(</span><span class="n">news_page</span><span class="p">)</span> <span class="ow">or</span> <span class="n">page</span> <span class="o">&gt;=</span> <span class="n">pages</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="n">page</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">page</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../../index.html">
    <img class="logo" src="../../../_static/scrapd-logo-128x152.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">Easily scrap APD traffic death repports</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=scrapd&repo=scrapd&type=star&count=False&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>







<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../README.html">ScrAPD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Detailed usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../CHANGELOG.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../CONTRIBUTING.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/modules.html">API Reference</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Rémy Greinhofer.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.2.0</a>
      
    </div>

    
    <a href="https://github.com/scrapd/scrapd" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>